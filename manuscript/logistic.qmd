# Classification with Logistic Regression {#classification}

This chapter shows how to use and interpret SHAP with logistic regression.
In this chapter you will learn:

- How to apply SHAP for classification.
- How to handle categorical features (also relevant for regression of course).
- That SHAP puts out one SHAP value not only for each instance and feature, but also for each class.


Differences from linear regression include:

- Two outcomes instead of one.
- Outcome is a probability [^no-probability].
- Non-linear function with option to scale to linear using log odds.

Logistic regression is a special case of multi-class classification and what you learn in this chapter applies to multi-class classifiers as well.
In general, for binary classification, we have two outputs: one probability output for the first class and one for the second.
However, since one class probability already defines the other's probability, you can work with just one of the probabilities.
Nonetheless, having two classes is a special case of having $k$ classes.

From the SHAP perspective, this is similar to regression, except the scale is the score output, not regression.

## The adult dataset

For the classification task, we will use the Adult dataset.
The UCI Adult dataset is widely used in machine learning tasks.
It contains demographic and socioeconomic data of individuals from the 1994 U.S. Census Bureau database, aiming to predict whether an individual's income is greater than or equal to \$50,000 per year.
The dataset includes features such as age, education level, work class, occupation, marital status, and more.
With approximately 32,000 observations, it contains both categorical and numerical features.
Fortunately, the `shap` package includes the adult dataset, simplifying its use in our example.


## Training the model

```{python}
import shap
from sklearn.model_selection import train_test_split

X, y = shap.datasets.adult()

X_train, X_test, y_train, y_test = train_test_split(
  X, y, test_size=0.2, random_state=1
)
```

In the next step, we train the model and compute the SHAP values.
If you have followed the previous chapters, you will notice something new here:

```{python}
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
import numpy as np

# Define the categorical and numerical features
cats = ['Workclass', 'Marital Status', 'Occupation',
        'Relationship', 'Race', 'Sex', 'Country']
nums = ['Age', 'Education-Num', 'Capital Gain',
        'Capital Loss', 'Hours per week']

# Define the column transformer
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), cats),
        ('num', StandardScaler(), nums)
    ])

# Define the pipeline
model = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=10000))
])

# Fit the pipeline to the training data
model.fit(X_train, y_train)

X_sub = shap.sample(X_train, 100)

ex = shap.Explainer(model.predict_proba, X_sub)
shap_values = ex(X_test.iloc[0:100])
```

The novelties: 
- We only use a subset of the training data as background dataset. This can help with computation speed at the cost of less accurate SHAP value estimates.
- Also, we apply SHAP not only to the model, but the entire pipeline. This is because we don't want the inputs to the model as basis for interpretation, because these are one-hot encoded and scaled features. Instead, we want the more interpretable "raw" features as basis of interpretation.

The adult dataset contains both categorical and numerical features.
Both are transformed before inputting them into the logistic regression model:

- Numerical features are standardized: $x_{j,std}^{(i)} = (x_j^{(i)} - \bar{x_j}) / sd(x_j)$,
- Categorical features are one-hot encoded: A feature with 1 column and 3 categories becomes 3 columns. e.g. category "3" may be encoded as (0,0,1).

After these two steps, our dataset has approximately 470 columns.
The numerical features, such as age, are no longer on an easily interpretable scale, so we would need to calculate what age 0.8 represents, for example.

However, the logistic regression model now works with these inputs.
This means that the coefficients are based on this transformed dataset.
If we were to use SHAP values directly on the logistic regression model, we would get 470 Shapley values.

Fortunately, there's a more clever approach:
We can combine the preprocessing and logistic regression into a pipeline and treat it as our model.
This is similar to functions:

- Our model is $Y = f(\tilde{X})$, where $\tilde{X}$ is the preprocessed data.
- We have our preprocessing steps, which we'll call $g$, and we can express the preprocessed data as $\tilde{X} = g(X)$.
- The less desirable option would be to use SHAP values on $f$.
- The better option is to define a new function $\tilde{f}(X) = f(g(X))$, where the input is $X$ and not $\tilde{X}$.
- We use SHAP values applied to $\tilde{f}$ instead of $f$.

This allows us to interpret the features in their original form.

::: {.callout-warning}

When preprocessing your data, consider which preprocessing steps you want to include as part of your model when calculating SHAP values.
In some cases, like standardization, it makes sense to include them in the model, while in other cases, like transformations that increase interpretability, it makes sense to exclude them.

:::

Another notable aspect is that the model's output is 2-dimensional instead of 1-dimensional.
This is reflected in the resulting `shap_values` variable, which gain another dimension.
Therefore we have to also indicate the class for which we want to access the SHAP values.

```{python}
class_index = 0
data_index = 1

sv = shap.Explanation(
  values = shap_values.values[data_index,:,class_index],
  base_values = shap_values.base_values[data_index,class_index],
  feature_names=X.columns,
  data=X_test.iloc[data_index]
)
shap.waterfall_plot(sv)
```

For this individual, the predicted likelihood of earning more than \$50k was 99.9% which is more than the expected 79%.
This plot reveals that the most influential feature was Marital Status (4 = married), which contributed 0.06.
The interpretation is mostly the same as for regression, only that the outcome is on the probability level and that we have to decide for which class we want to interpret the SHAP values.

Let's examine the SHAP values for the alternative class.

```{python}
class_index = 1

sv = shap.Explanation(
  values = shap_values.values[data_index,:,class_index],
  base_values = shap_values.base_values[data_index,class_index],
  feature_names=X.columns,
  data=X_test.iloc[data_index]
)
shap.waterfall_plot(sv)
```

This plot is identical to the previous one, except all SHAP values are multiplied by -1.
This makes sense since the probabilities for both classes must sum to 1.
Thus, a factor that increases the classification by 0.11 for class >50k decreases the classification by 0.11 for class <=50k.
We only need to choose one of the two classes.
This changes when we have three or more classes, see the [Image Chapter](#image) for a multi-class example.

## Interpreting log odds

For logistic regression, it is common to interpret the model in terms of log odds rather than probability.

To do this, the explainer has a `link` argument, which defaults to the identity link $l(x) = x$.
A useful choice for classification is the logit link: $l(x) = log\left(\frac{x}{1 - x}\right)$.

```{python}
ex_logit = shap.Explainer(
  model.predict_proba, X_sub, link=shap.links.logit
)
sv_logit = ex_logit(X_test.iloc[0:100])
class_index = 0

sv = shap.Explanation(
  values = sv_logit.values[data_index,:,class_index],
  base_values = sv_logit.base_values[data_index,class_index],
  feature_names=X.columns,
  data=X_test.iloc[data_index]
)

shap.waterfall_plot(sv)
```

Interpretation:
A marital status of 0 (married) contributes +1.36 to the log odds of >50k versus <=50k compared to the average prediction.
The advantage of log odds is that the model is linear at this level, allowing for simpler solutions.

However, one of SHAP values' strengths is its applicability at the probability level.
Log odds can be difficult to interpret.

::: {.callout-note}

If you're concerned with the probability outcome, avoid using the logit link and opt for the identity link (which is the default behavior).
The logit space is more appropriate if you're interested in "evidence" in an information-theoretic sense, even if the effect in probability space isn't substantial.

:::

Example:
A shift from 80% to 90% is large in probability space, while a change from 98% to 99.9% is relatively small.

In probability space, the differences are 0.10 versus 0.019.
In logit space, we have:

- $log(0.9/0.1) - log(0.8/0.2) \approx 0.8$ and
- $log(0.999/0.001) - log(0.98/0.02) \approx 3$

In logit space, the step is significantly larger.
This occurs because the logit compresses near 0 and 1, causing changes in the middle of probability space to appear larger.

So, which one should you choose?
If you mostly care about probabilities, and a jump from 50% to 51% is as important to you as from 99% to 100%, opt for the default and use the identity link.
However, if changes in extreme probabilities near 0 and 1 are more crucial for the application, go with logits.

You can also see the difference in step sizes visualized in the following Figure.

![Probabilities versus Logits](images/logits.jpg)

## Understanding the data globally

To finish up the model interpretation, let's have a look at the global importances and effects with the summary plot:

```{python}
shap.summary_plot(
  shap_values.values[:,:,1],
  features = X_test.iloc[0:100,:],
  feature_names=X.columns
)
```

We can observe that Marital Status and Capital Gain are the two most important features (on the log odds scale).
For some individuals, Capital Gain has very large effects, indicating that high values of capital gain lead to high SHAP values and, consequently, a high probability of earning more than 50k.

<!--

The categories for marital status include: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, and Married-AF-spouse.

```{python}
#| eval: false
mapping = {
  0: "Married-civ-spouse",
  1: "Divorced",
  2: "Never-married",
  3: "Separated",
  4: "Widowed",
  5: "Married-spouse-absent",
  6: "Married-AF-spouse"
}
fv = [mapping[X.iloc[i,:]] for i in range(100)]
```

```{python}
shap.dependence_plot(
  "Marital Status",
  shap_values.values[:,:,0],
  features = X.iloc[0:100,:]
)
```
-->

[^no-probability]: While the output is a number between 0 and 1, classifiers are often not so well calibrated, so be careful with interpreting the output as a probability in the real world.
