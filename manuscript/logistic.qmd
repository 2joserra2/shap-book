# Binary Classification with Logistic Regression

This chapter demonstrates how to use and interpret SHAP with logistic regression.

Differences from linear regression include:

- Two outcomes instead of one
- Outcome is a probability
- Non-linear function with option to scale to linear using log odds

Logistic regression is a special case of multi-class classification, which you will learn about in the next chapter.

In general, for binary classification, we have two outputs: one probability output for the first class and one for the second.
However, since one class probability already defines the other's probability, you can work with just one of the probabilities.
Nonetheless, having two classes is a special case of having $k$ classes.

From the SHAP perspective, this is similar to regression, except the scale is the score output, not regression.

_TODO: Merge this part with getting started chapter_

## The Adult Dataset

For the classification task, we will use the Adult dataset.
The UCI Adult dataset is widely used in machine learning tasks.
It contains demographic and socioeconomic data of individuals from the 1994 U.S. Census Bureau database, aiming to predict whether an individual's income is greater than or equal to \$50,000 per year.
The dataset includes features such as age, education level, work class, occupation, marital status, and more.
With approximately 32,000 observations, it contains both categorical and numerical features.
The UCI Adult dataset is often used for classification tasks and has been employed in numerous research studies.

## Training the Model

```{python}
import shap
from sklearn.model_selection import train_test_split

X, y = shap.datasets.adult()

X_train, X_test, y_train, y_test = train_test_split(
  X, y, test_size=0.2, random_state=1
)
```

In the next step, we train the model and compute the Shapley values.
If you have followed the previous chapters, you will notice something new here:
```{python}
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
import numpy as np

# Load the Adult dataset
X, y = shap.datasets.adult()

# Define the categorical and numerical features
categorical_features = ['Workclass', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Country']
numerical_features = ['Age', 'Education-Num', 'Capital Gain', 'Capital Loss', 'Hours per week']

# Define the column transformer
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), categorical_features),
        ('num', StandardScaler(), numerical_features)
    ])

# Define the pipeline
model = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=10000))
])

# Fit the pipeline to the training data
model.fit(X_train, y_train)

X_sub = shap.sample(X_train, 100)

ex = shap.Explainer(model.predict_proba, X_sub)
shap_values = ex(X_test.iloc[0:100])
```

The novelty: 
We apply SHAP not only to the model, but the entire pipeline, for a good reason.

The adult dataset contains both categorical and numerical features.
Both are transformed before inputting them into the logistic regression model:

- Numerical features are standardized: $x_{j,std}^{(i)} = (x_j^{(i)} - \bar{x_j}) / sd(x_j)$,
- Categorical features are one-hot encoded: A feature with 1 column and 10 different values becomes 10 columns.
After these two steps, our dataset has approximately 470 columns.
The numerical features, such as age, are no longer on an easily interpretable scale, so we would need to calculate what age 0.8 represents, for example.

However, the logistic regression model now works with these inputs.
This means that the coefficients are based on this transformed dataset.
If we were to use Shapley values directly on the logistic regression model, we would get 470 Shapley values.

Fortunately, there's a more clever approach:
We can combine the preprocessing and logistic regression into a pipeline and treat it as our model.
This is similar to functions:

- Our model is $Y = f(\tilde{X})$, where $\tilde{X}$ is the preprocessed data.
- We have our preprocessing steps, which we'll call $g$, and we can express the preprocessed data as $\tilde{X} = g(X)$
- The less desirable option would be to use Shapley values on $f$
- The better option is to define a new function $\tilde{f}(X) = f(g(X))$, where the input is $X$ and not $\tilde{X}$

This allows us to interpret the features in their original form.

::: {.callout-warning}

When preprocessing your data, consider which preprocessing steps you want to include as part of your model when calculating Shapley values.
In some cases, like standardization, it makes sense to include them in the model, while in other cases, like transformations that increase interpretability, it makes sense to exclude them.

:::

Another notable aspect is that the model's output is 2-dimensional instead of 1-dimensional.
This is reflected in the resulting Shapley values, which gain another dimension:

```{python}
class_index = 0
data_index = 1
```

sv = shap.Explanation(
  values = shap_values.values[data_index,:,class_index],
  base_values = shap_values.base_values[data_index,class_index],
  feature_names=X.columns,
  data=X_test.iloc[data_index]
)
shap.waterfall_plot(sv)

```

For this individual, the predicted likelihood of earning more than $50k was 0.978.
This plot reveals that the most influential feature was Marital Status, which had a value of 0, indicating married, and it increased the predicted probability by 0.11 (11%) compared to the average probability of 0.732.


On the other hand, we can examine the Shapley values for the alternative class.

```{python}
class_index = 1

sv = shap.Explanation(
  values = shap_values.values[data_index,:,class_index],
  base_values = shap_values.base_values[data_index,class_index],
  feature_names=X.columns,
  data=X_test.iloc[data_index]
)
shap.waterfall_plot(sv)
```

This plot is identical to the previous one, except all Shapley values are multiplied by -1.
This makes sense since the probabilities for both classes must sum to 1.
Thus, a factor that increases the classification by 0.11 for class >50k decreases the classification by 0.11 for class <=50k.
We only need to choose one of the two classes.
This changes when we have three or more classes, as discussed in the [multiclass chapter](multiclass).

## Interpreting log odds

For logistic regression, it is common to interpret the model in terms of log odds rather than probability.

To do this, the explainer has a `link` argument, which defaults to the identity link $l(x) = x$.
A useful choice for classification is the logit link: $l(x) = log(\frac{x}{1 - x})$.
```{python}
ex_logit = shap.Explainer(model.predict_proba, X_sub, link=shap.links.logit)
shap_values_logit = ex_logit(X_test.iloc[0:100])
class_index = 0

sv = shap.Explanation(
  values = shap_values_logit.values[data_index,:,class_index],
  base_values = shap_values_logit.base_values[data_index,class_index],
  feature_names=X.columns,
  data=X_test.iloc[data_index]
)

shap.waterfall_plot(sv)
```

Interpretation:
A marital status of 0 (married) contributes +1.36 to the log odds of >50k versus <=50k compared to the average prediction.
The advantage of log odds is that the model is linear at this level, allowing for simpler solutions.

However, one of Shapley values' strengths is its applicability at the probability level.
Log odds can be difficult to interpret.

::: {.callout-note}

If you're concerned with the probability outcome, avoid using the logit link and opt for the identity link (which is the default behavior).
The logit space is more appropriate if you're interested in "evidence" in an information-theoretic sense, even if the effect in probability space isn't substantial.

:::

Example:
A shift from 80% to 90% is significant in probability space, while a change from 98% to 99.9% is relatively small.

In probability space, the differences are 0.10 versus 0.019.
In logit space, we have:

- $log(0.9/0.1) - log(0.8/0.2) \approx 0.8$ and
- $log(0.999/0.001) - log(0.98/0.02) \approx 3$
In logit space, the step is significantly larger.
This occurs because the logit compresses near 0 and 1, causing changes in the middle of probability space to appear larger.

So, which one should you choose?
If you mostly care about probabilities, and a jump from 50% to 51% is as important to you as from 99% to 100%, opt for the default and use the identity link.
However, if changes in extreme probabilities near 0 and 1 are more crucial for the application, for instance, if a feature pushes the probability from 0.98 to 0.99.

## Understanding the data globally

Global SHAP plots enable us to see how features impact the overall predictions in the model.

```{python}
shap.summary_plot(
  shap_values.values[:,:,1],
  features = X_test.iloc[0:100,:],
  feature_names=X.columns
)
```

We can observe that Marital Status and Capital Gain are the two most important features.
For some individuals, capital gain has very large effects, indicating that high values of capital gain lead to high Shapley values and, consequently, a high probability of earning more than 50k.

The categories for marital status include: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, and Married-AF-spouse.

```{python}
#| eval: false
mapping = {
  0: "Married-civ-spouse",
  1: "Divorced",
  2: "Never-married",
  3: "Separated",
  4: "Widowed",
  5: "Married-spouse-absent",
  6: "Married-AF-spouse"
}
fv = [mapping[X.iloc[i,:]] for i in range(100)]
```

```{python}
shap.dependence_plot(
  "Marital Status",
  shap_values.values[:,:,0],
  features = X.iloc[0:100,:]
)
```
TODO: Investigate the split's purpose
