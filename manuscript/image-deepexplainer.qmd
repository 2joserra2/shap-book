# Explain MNIST Model with DeepExplainer and GradientExplainer

In the previous chapter we have seen an example of the Partition explainer where larger patches of an image were treated as a feature for SHAP.

In this chapter we explain the classifications of an image classifier as well.

This time, however, we take an approach more similar to the tabular data.
That means two things:

- one Shapley value for each input pixel
- feature absence (pixel absence) is simulated by replacement from a pixel from an image which comes from a background dataset.

The network gets as input the individual pixels, but that doesn't mean we have to use the same granularity for the explanations.

And since it's a neural network, we have two model-specific tools available:

- the gradient explainer, since a neural network is usually based on gradients
- the deep explainer which specifically makes use of neural networks layers to backpropagate the Shapley values

Both are explained in more detail in the [estimation chapter](#estimation).
For the data we will be using the MNIST data.
The MNIST data set is a collection of 70,000 handwritten digits (0-9), each represented as a 28x28 pixel grayscale image.
The goal of the MNIST task is to develop a machine learning algorithm that can accurately classify these images into their corresponding digit categories.
This is a well-known benchmark problem in the field of machine learning, and it has been used as a standard for evaluating the performance of various algorithms, such as neural networks, decision trees, and support vector machines.
The MNIST task is a supervised learning problem, where the algorithm is trained on a subset of the data set and then tested on a separate set to evaluate its accuracy.
The MNIST data set has been widely used for research in machine learning, computer vision, and pattern recognition.

But why didn't I pick the ImageNet data as in the example before?
Because using pixel-wise explanations with Gradient or Deep explainer also means that we sample absent features using a background dataset.

Because bascially there are two options to replace a value with images:

- We could replace them from background data
- Or we could replace them with some reference, which could be blurring them or replacing them with grey pixels (or some other "neutral" color)

But imagine for the imagenet data: We have the image of a burger and then replace the "absent" pixels with pixels from a dog image.
Would be weird.
For MNIST, however, it's a more sensible approach, since the digits are more similar to each other and by replacing some of the pixels of a "2" with pixels of a "3" doesn't generate completely weird images.
I'm aware that this is a rather vague argument, but in general explanations for images are a bit more wonky or difficult.

Anyways, let's get started.
First, we train a neural network from scratch, using tensorflow:

```{python}
#| output: false
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.utils import to_categorical

# Load the MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Preprocess the data
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Define the model architecture
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, batch_size=128, epochs=5, validation_data=(x_test, y_test))
score = model.evaluate(x_test, y_test, verbose=0)
```
Let's evaluate the model.

```{python}
# Evaluate the model on the test set
print('Test loss:', score[0])
print('Test accuracy:', score[1])

```

CONTINUE HERE

TODO: INTERPRET los

## Gradient explainer

Next, we explain it with shap:

```{python}
import shap
import time

# x_test is quite big, let's just take a sample
x_sample = shap.sample(x_test, 500)

# since we have two inputs we pass a list of inputs to the explainer
explainer = shap.GradientExplainer(model, data = x_sample)

# we explain the model's predictions on the first three samples of the test set
start_time = time.time()
shap_values = explainer.shap_values(x_test[:3])
gradient_time = time.time() - start_time
```

Let's shortly talk about the output.
So the shap_values are a list of length of the number of classes.
It's 10 classes, from "0" to "9", so we get a list of length 10:

```{python}
print(len(shap_values))
```

And for each of the model output, we get the shapley values:

```{python}
print(shap_values[0].shape)
```

First dimension is the number of images for which we computed the shapley values.
Then second, third and fourth dimensions are the shapley values in the form of an image, since the input data was an image.

Let's plot the shap values:

```{python}
shap.image_plot(shap_values, x_test[:3])
```

##  Deep explainer

We do the same, but use the DeepExplainer this time

```{python}
#| output: false
explainer = shap.DeepExplainer(model, data = x_sample)
start_time = time.time()
shap_values = explainer.shap_values(x_test[:3])
deep_time = time.time() - start_time
```

And plot the results again:

```{python}
shap.image_plot(shap_values, x_test[:3])
```

TODO: Interpret results


TODO: Compare results, qualitatively the results with gradient explainer

Comparing with 


## Time comparison between deep explainer

We measured time for both gradient and deep explainer.

Let's see:

```{python}
print("Gradient explainer: ", round(gradient_time, 2))
print("Deep explainer: ", round(deep_time, 2))
```

IN THEORY, to get a good time comparison, you have to repeat the calls a couple hundreds of times, not use other programs at the same time, yada yada yada.
So I did this comparison just once and on my Macbook with M1 chip.
BUT, the difference is clear here.

Also it's just on my CPU, so anytime we call the model, it's not in the most effective way because there is no GPU involved. 


