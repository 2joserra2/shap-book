# Estimating Shapley Values - An Overview {#estimation-overview}

There is more than one way to estimate Shapley values.
This chapter gives an overview of the estimation methods, for a deeper dive go to the [Appendix](#estimation).

The estimation methods differ in:

- Speed
- Accuracy, usually as a trade-off with speed
- Applicability for different models

::: {.callout-note}
No matter which estimation method you choose, you'll get the same Shapley values, at least in expectation.
Exceptions: Linear SHAP with `feature_perturbation='correlation_dependent'` and Tree Explainer with `feature_perturbation='tree_path_dependent'`.
:::

## Overview of the many estimators

Here is an overview of the explainers, for your convenience:

| Explainer | How it works | Model | Background Data | Inspiration |
| --- | --- | --- | --- | --- |
| Exact | Iterates through all background data and some coalitions. | Agnostic | Yes | - |
| Sampling | Samples coalitions of features. | Agnostic | Yes | - |
| Permutation | Samples permutations of feature values. | Agnostic | Yes | - |
| Linear | Explains linear models by multiplying feature values by their weights. | Linear | Yes | - |
| Additive | Explains additive models. | GAMs | Yes | - |
| Kernel | Uses a locally weighted linear regression to explain the output of any function. | Agnostic | Yes | LIME |
| Tree (interventional) | Recursively iterates tree paths. | Tree-based | No | - |
| Tree (path dependent) | Recursively iterates hybrid paths. | Tree-based | Yes | - |
| Gradient | Explains models by computing the gradient of the output with respect to the inputs. | Gradient-based | Yes | Input Gradient |
| Deep | Explains deep learning models by attributing the output to input features using the gradient of the output with respect to the inputs. | Neural Networks | Yes | DeepLIFT |
| Partition | Calculates Shapley values for a hierarchy of features. | Agnostic | Yes | Owen values |

## When to use which estimator

The big question: When should you use which explainer?

Here is a quick guide:

- In most cases, you can just use the `Explainer` as it will usually select the best explainer based on the provided model. Best usually means fastest.
- The general recommendation is to use a model-specific explainer if possible; otherwise, the permutation explainer is the best choice for most model-agnostic options. That's what the `auto` option does.
- Avoid the Kernel explainer -- it's no longer the default because the Permutation explainer is faster.
- Tree SHAP is fast, so always consider tree-based models in your model selection process. It is best practice to include a tree-based solution in the model comparison.
- Use the partition explainer for correlated features and applications like image processing.
