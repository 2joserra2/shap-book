# Preface

I've written Interpretable Machine Learning.
Funnily enough, SHAP hasn't been one of the chapters for a long time.
Then I made a Twitter survey and people said that shap is the most popular.
Shap is incredibly popular library and technique for machine learning model interpetation.

But shap also has lots of criticism.
Difficult to interpret, expensive to compute.
I also have a difficult past with shap:
Being a research on interpretable machine learning, I often got annoying feedback from reviewers.
They said: Why don't you research shap instead of what you are doing.
Because shap is "better".

But I still decided to write this book that you have now.
I have this love-hate-relationship with shap.
It's overall a great tool.
But it's not the cure-all that some people believe it is.

This mix makes me the right person to write this book:
I can understand what shap is all about.
I can see and explain what it can be used for.
But it doesn't hold me in its hype-grip.
And at the appropriate placed, I can tell you about alternative interpretation methods.

But why write it anyways?
Because it's so popular.
There's lots and lots of material out there.
But no definitive source that you can trust.
And over the years I've build up a lot of knowledge about shap.




