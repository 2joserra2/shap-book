# The Correlation Problem {#correlation}

::: {.callout-tip appearance="simple"}

By the end of this chapter, you will be able to:

- Describe the challenge of correlated features for SHAP
- Pick solutions to reduce the correlation problem

:::


SHAP values have a subtle but significant issue when dealing with correlated features:
simulating feature absence by replacing them with sampled values from the background data can produce unrealistic data points.
These unrealistic data points are then used to generate explanations, which is problematic for several reasons:

- Involving unrealistic or unlikely data points in the explanation may not be desirable.
- There could be a conceptual issue with physically impossible data points (e.g., a 2-meter tall person weighing 10 kg).
- The model may not have been trained on data in these areas and might produce unexpected results.

In this chapter, we will first dive into the problem in more detail using a small simulation, followed by discussing possible solutions.

## Correlated features cause extrapolation

To illustrate this issue, I simulated two strongly correlated features, $X_1$ and $X_2$.
Suppose a machine learning model is later trained on this data.
We will not train a model, but rather examine how sampling background data can be problematic.

```{python}
import numpy as np

p = 0.9
mean = [0, 0] # mean vector
cov = [[1, p], [p, 1]] # covariance matrix
n = 100 # number of samples

x1, x2 = np.random.multivariate_normal(mean, cov, n).T
```

Next, let's create a data point for which we will simulate drawing from the background data.

```{python}
point = (-1.7, -1.7)
```

I'm interested in the SHAP value for feature $X_1$.
I will demonstrate how SHAP values sample from the marginal distribution and compare that to what sampling from the conditional distribution would look like.

```{python}
#| label: fig-sampling
#| fig-cap: "Marginal and conditional sampling"
import matplotlib.pyplot as plt
# set number of samples for conditional distribution
m = 15

# create marginal and conditional distribution
x2_cond = np.random.normal(
  loc=p*point[0], scale=np.sqrt(1-p**2), size=m
)
x2_marg = np.random.choice(x2, size=m)

# create scatter plot with fixed x1 and variable x2
plt.subplot(121)
plt.scatter(x1, x2, color='black', alpha=0.1)
plt.scatter(np.repeat(point[0], m), x2_cond, color='green')
plt.scatter(point[0], point[1], color='red')
plt.subplot(122)
plt.scatter(x1, x2, color='black', alpha=0.1)
plt.scatter(np.repeat(point[0], m), x2_marg, color='blue')
plt.scatter(point[0], point[1], color='red')
plt.xlabel('x1')
plt.ylabel('x2')

plt.show()
```

The plot on the right illustrates sampling from the marginal distribution: we ignore the correlation between $X_1$ and $X_2$ and sample $X_2$ independently from $X_1$.
Marginal sampling in this correlated case creates new data points outside of the distribution.
This is what occurs with SHAP values as we have used them throughout the book.
On the left, we can see conditional sampling.
Conditional sampling means that we respect the distribution of $X_2$, given that we already know the value for $X_1$ and sample from $P(X_2 | X_1)$ instead of $P(X_2)$.
Conditional sampling preserves the distribution while marginal sampling may hurt it when features are correlated.

## A philosophical problem

Before discussing solutions, let's explore the correlation problem further.
The problem of correlation and extrapolation is not just a technical challenge but also a philosophical one: do we want the interpretation to reflect the modeled relations or the data?

Consider this: What does it **mean** when features are correlated and what are the consequences for interpretation?
From an information theoretic perspective, correlation means that two features share information.
If they share information, it makes sense that we cannot simply sample one of the features without considering the correlated feature.

For example, let's say we have two strongly correlated features: rainfall yesterday and cloudiness yesterday.
If it rained yesterday, we know it must have been cloudy - these features are correlated.
How can we isolate the effect of rain while ignoring the cloudiness?

## Solution: Reduce correlation in the model

While it may seem overly simplistic, avoiding the correlation problem can be achieved by eliminating correlated features.
This solution requires flexibility in training the model with a different set of features.
If you have the option to change the features, we can leverage a wider range of techniques to reduce the number of features used:

- Employ feature selection methods, particularly those that eliminate correlated features.
- Remove features with minimal variance.
- Utilize dimensionality reduction techniques. But this might come with a loss of interpretability, for example, principal component analysis creates features that are difficult to interpret.
- Apply feature engineering to decrease correlation. For example, if you have the features "apartment rent" and "number of rooms", they will be correlated. Instead you can decorrelate them by turning the rent into "rent per square meter". 
- Combine features: Perhaps you have the amount of rain in the morning and afternoon as separate features. Maybe daily rainfall is sufficient? Test it out.

Reducing correlated features and the overall number of features can significantly benefit model fitting.
For each of these steps, you can assess how they affect predictive performance, aiding in your decision-making for possible trade-offs.

## Solution: Combined explanation of correlated features with Partition explainer

Instead of using the `Independent` explainer, opt for the `Partition` explainer.
The Partition explainer generates a feature hierarchy presented as a tree.
While any metric could be used to produce the hierarchy, it should be some correlation-based metric that hierarchically clusters the features, like Pearson correlation.

Within this hierarchy, SHAP values are calculated recursively.
This procedure is actually it's own game, called Owen's game and we get Owen values back.
Owen values are tightly connect to Shapley values, as we will see in the following example.
Let's say for the apartment example we have the following binary tree of correlations:

```{mermaid}

graph TB
    A[X]
    S[size, cat, park]
    F[floor]
    C[park]
    P[size,cat]
    Q[cat]
    R[size]
    A --> S
    A --> F
    S --> C
    S --> P
    P --> Q
    P --> R

```


- Cat and size are most strongly correlated.
- Both are slightly correlated with the park feature.
- The floor feature is correlated with neither of the features.


To compute Owen values, aka hierarchical Shapley values, we start on top and have two feature groups: {size,cat,park} and {floor}.
We treat both groups as players and compute their SHAP values $\phi_{\text{size,cat,park}}$ and $\phi{floor}$.
In the next recursion, we go down and now split up the $\phi_{\text{size,cat,park}}$ among the groups {park} and {size, cat}, again like we would compute SHAP, but with possibly groups as players.
And then, go down two {cat} and {size}.
The Partition explainer doesn't fully eliminate the correlation problem.
As we go deeper down the correlation tree, we start to also break up stronger correlated features to recursively compute the Owen's value.
However, it's reduced, since we only try to explain the group's SHAP value and permuted fewer features.

Owens game alters the complexity from $\mathcal{O}(2^p)$ to $\mathcal{O}(p^2)$ (when the clustering tree is balanced), where $p$ is the number of input features for the model.

## Solution: Conditional sampling

As hinted in @fig-sampling, it's also possible to use conditional sampling.

A brief example:

- We have four features $X_1$ to $X_4$.
- Compute the SHAP value for $X_1$.
- During sampling, one of the coalitions we add $X_1$ to is $\{X_2\}$.
- Compute the predictions for the teams $\{X_2\}$ and $\{X_1, X_2\}$.
- The absent features are $\{X_1, X_3, X_4\}$ and $\{X_3, X_4\}$, which are sampled from the background data.
- Sampling can be either from:
  - $P(X_1, X_3, X_4)$ and $P(X_3, X_4)$ (marginal sampling), or
  - $P(X_1, X_3, X_4 | X_2)$ and $P(X_3, X_4| X_1, X_2)$ (conditional sampling)

Conditional sampling avoids the extrapolation problem.
@aas2021explaining suggested incorporating conditional sampling in KernelSHAP.
However, conditional sampling is easier said than done, considering that supervised machine learning focuses on learning $P(Y|X_1, \ldots, X_p)$, and we now need to learn more complex distributions for multiple variables.
Typically, simplifying assumptions for the conditional distributions are used to make sampling easier, as done by @aas2021explaining:

- Use multivariate Gaussians.
- Employ Gaussian copulas.
- Apply kernel estimators (if there are not too many dimensions).

The paper proposed more techniques, but these are the key ones.

::: {.callout-warning}

Switching the sampling from marginal to conditional alters the value function to a conditional value function:

$$v_{f,x^{(i)}}(S) = \int f(x^{(i)}_S \cup X_C)d\mathbb{P}_{X_{C}|X_S=x^{(i)}_S} - \mathbb{E}(f(X))$$

This changes the game.
For instance, the resulting SHAP values may appear to no longer adhere to the Dummy axiom, as unused features like $\beta_j=0$ in a linear model can suddenly have non-zero SHAP values.
However, conditional SHAP doesn't actually violate the Dummy axiom, since based on the new payout using conditional distributions, they still qualify as (conditional) SHAP values.
Without correlation, marginal and conditional SHAP are the same, because then $P(X_1) = P(X_1|X_2)$.

:::

If you want to use conditional sampling in `shap`, you can use the Linear explainer with the option `feature_pertubation='correlation_dependent'`.
The tree explainer has a similar option called `feature_pertubation='tree_path_dependent'` which relies on the splits in underlying tree-based model to make sure that the Monte Carlo samples for SHAP are not extrapolating.
But I recommend against the tree-path option, since it doesn't actually model the conditional distribution but something in between and doesn't approximate the conditional SHAP values well [@aas2021explaining].


Whether a conditional SHAP interpretation is desirable depends on your interpretation goals.
If your objective is to audit the model, marginal sampling might be more appropriate.
If you want to better understand the data, conditional sampling could be the better option.
This trade-off is also characterized as being true to the model (marginal sampling) or true to the data (conditional sampling) [@chen2020true].
This concept is further discussed by @sundararajan2020many.


