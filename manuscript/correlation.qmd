# The Correlation Problem {#correlation}

Shapley values have a subtle but significant issue when dealing with correlated features:
simulating feature absence by replacing them with sampled values from the background data can produce unrealistic data points.
These unrealistic data points are then used to generate explanations, which is problematic for several reasons:

- Involving unrealistic or unlikely data points in the explanation may not be desirable.
- There could be a conceptual issue with physically impossible data points (e.g., a 2-meter tall person weighing 10 kg).
- The model may not have been trained on data in these areas and might produce unexpected results.

In this chapter, we will first delve into the problem in more detail using a small simulation, followed by discussing possible solutions.

## Correlated features cause extrapolation

To illustrate this issue, I simulated two strongly correlated features, $X_1$ and $X_2$.
Suppose a machine learning model is later trained on this data.
We will not train a model, but rather examine how sampling background data can be problematic.

```{python}
import numpy as np

p = 0.9
mean = [0, 0] # mean vector
cov = [[1, p], [p, 1]] # covariance matrix
n = 100 # number of samples

x1, x2 = np.random.multivariate_normal(mean, cov, n).T
```

Next, let's create a data point for which we will simulate drawing from the background data.

```{python}
point = (-1.7, -1.7)
```

I'm interested in the Shapley value for feature $X_1$.
I will demonstrate both what Shapley values do and how background data sampling should appear when respecting the conditional distribution of the data.
```{python}
#| label: fig-sampling
#| fig-cap: "Marginal and conditional sampling"
import matplotlib.pyplot as plt
# set number of samples for conditional distribution
m = 15

# create marginal and conditional distribution
x2_cond = np.random.normal(
  loc=p*point[0], scale=np.sqrt(1-p**2), size=m
)
x2_marg = np.random.choice(x2, size=m)

# create scatter plot with fixed x1 and variable x2
plt.subplot(121)
plt.scatter(x1, x2, color='black', alpha=0.1)
plt.scatter(np.repeat(point[0], m), x2_cond, color='green')
plt.scatter(point[0], point[1], color='red')
plt.subplot(122)
plt.scatter(x1, x2, color='black', alpha=0.1)
plt.scatter(np.repeat(point[0], m), x2_marg, color='blue')
plt.scatter(point[0], point[1], color='red')
plt.xlabel('x1')
plt.ylabel('x2')

plt.show()
```

The plot above illustrates that when we ignore the correlation between $X_1$ and $X_2$ and sample $X_2$ independently from $X_1$, we create new data points outside of the distribution.
This is what occurs with Shapley values.
On the left, we can see what sampling from $P(X_2 | X_1)$ instead of $P(X_2)$ would look like.
This conditional sampling will also be part of one of the solutions.

## A philosophical problem

Before delving into solution details, let's explore the issue further.
The problem of correlation and extrapolation is not just a technical challenge but also a philosophical one: do we want the interpretation reflect the modeled relations or the data?

Consider this: What does it **mean** when features are correlated, and what are the consequences for interpretation?
From an information theoretic perspective, correlation means that two features share information.
If they share information, it makes sense that we cannot simply sample one of the features without considering the correlated feature.

For example, let's say we have two strongly correlated features: rainfall yesterday and cloudiness yesterday.
If it rained yesterday, we know it must have been cloudy - this is correlation.
How can we isolate the effect of rain while ignoring the cloudiness?

# Solution: Reduce correlation in the model

While it may seem overly simplistic, avoiding the correlation problem can be achieved by eliminating correlated features.
This solution requires flexibility in training the model with a different set of features.
If you have the option to change the features, we can leverage a wider range of techniques to reduce the number of features used:

- Employ feature selection methods, particularly those that eliminate correlated features.
- Remove features with minimal variance.
- Utilize dimensionality reduction techniques. But this might come with a loss of interpretability, for example, principal component analysis creates difficult to interpret features.
- Apply feature engineering to decrease correlation. For example, if you have the features "apartment rent" and "number of rooms", they will be correlated. Instead you can decorrelate them by using turning the rent into "rent per square meter". 
- Combine features: Perhaps you have the amount of rain in the morning and afternoon as separate features. Maybe daily rainfall is sufficient? Test it out.

Reducing correlated features and the overall number of features can significantly benefit model fitting.
For each of these steps, you can assess how much they reduce or potentially enhance model performance, aiding in your decision-making for possible trade-offs.

## Solution: Combined explanation of correlated features

Instead of using the `Independent` explainer, opt for the `Partition` explainer.
By default, the `Partition` explainer groups features based on correlation, but you can also define your own feature groupings.

The Partition explainer generates a feature hierarchy based on a provided distance matrix or custom groupings.
Within this hierarchy, Shapley values are calculated recursively.
This alters the complexity from $\mathcal{O}(2^p)$ to $\mathcal{O}(p^2)$ (when the clustering tree is balanced), where $p$ is the number of input features for the model.

This specific type of game is called the Owen game.
The benefit is that for groups of correlated features, we obtain a single Shapley value for interpretation.

## Solution: Conditional sampling

As hinted in @fig-sampling, it's also possible to use conditional sampling.

A brief example:

- We have four features $X_1$ to $X_4$.
- Compute the Shapley value for $X_1$.
- During sampling, one of the coalitions we add $X_1$ to is $\{X_2\}$.
- Compute the predictions for the teams $\{X_2\}$ and $\{X_1, X_2\}$.
- The absent features are $\{X_1, X_3, X_4\}$ and $\{X_3, X_4\}$, which are sampled from the background data.
- Sampling can be either from:
  - $P(X_1, X_3, X_4)$ and $P(X_3, X_4)$ (marginal sampling), or
  - $P(X_1, X_3, X_4 | X_2)$ and $P(X_3, X_4| X_1, X_2)$ (conditional sampling)

Conditional sampling avoids the extrapolation problem.
@aas2021explaining suggested incorporating conditional sampling in KernelSHAP.
However, conditional sampling is easier said than done, considering that supervised machine learning focuses on learning $P(Y|X_1, \ldots, X_p)$, and we now need to learn more complex distributions for multiple variables.
Typically, simplifying assumptions for the conditional distributions are used to make sampling easier, as done by @aas2021explaining:

- Use multivariate Gaussians.
- Employ Gaussian copulas.
- Apply kernel estimators (if there are not too many dimensions).

The paper proposed more techniques, but these are the key ones.

::: {.callout-warning}

Switching the sampling from marginal to conditional alters the game payout.
For instance, the resulting Shapley values may appear to no longer adhere to the Dummy axiom, as unused features like $\beta_j=0$ in a linear model can suddenly have non-zero Shapley values.
However, this doesn't actually violate the Dummy axiom, since based on the new payout using conditional distributions, they still qualify as Shapley values.
And it only happens if features are correlated.
Without correlation, marginal and conditional sampling work the same, because then $P(X_1) = P(X_1|X_2)$.

:::

As mentioned above, the Shapley game changes and features not utilized by the model can have non-zero Shapley values.

Whether this is desirable depends on your interpretation goals.
If your objective is to audit the model, marginal sampling might be more appropriate.
If you want to better understand the data, conditional sampling could be the better option.
This trade-off is also characterized as being true to the model (marginal sampling) or true to the data (conditional sampling) [@chen2020true].
This concept is further discussed by @sundararajan2020many.


