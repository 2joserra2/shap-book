# Theory of Shapley Values

This chapter will be heavy on theory.
Who could have guessed based on the title?
Anyways, you don't have to necessarily read the chapter if you just want to use the Shapley values.
It's for you if you want to dive deeper into the mathematics and algorithms behind Shapley values.

We'll build it up from the beginning.
And let's start with a linear prediction model, because here again it will be simpler to understand.

## For linear prediction problems

Our goal in this section: define Shapley values when the underlying model is just a linear regression model.
We are interested in how each feature affects the prediction of a data point.
In a linear model it is easy to calculate the individual effects.
Here is what a linear model prediction looks like for one data instance:

$$\hat{f}(x)=\beta_0+\beta_{1}x_{1}+\ldots+\beta_{p}x_{p}$$

where x is the instance for which we want to compute the contributions.
Each $x_j$ is a feature value, with j = 1,...,p.
The $\beta_j$ is the weight corresponding to feature j.

The contribution $\phi_j$ of the j-th feature on the prediction $\hat{f}(x)$ is:

$$\phi_j(\hat{f})=\beta_{j}x_j-E(\beta_{j}X_{j})=\beta_{j}x_j-\beta_{j}E(X_{j})$$

where $E(\beta_jX_{j})$ is the mean effect estimate for feature j.
The contribution is the difference between the feature effect minus the average effect.
Nice!
Now we know how much each feature contributed to the prediction.
If we sum all the feature contributions for one instance, the result is the following:

\begin{align*}\sum_{j=1}^{p}\phi_j(\hat{f})=&\sum_{j=1}^p(\beta_{j}x_j-E(\beta_{j}X_{j}))\\=&(\beta_0+\sum_{j=1}^p\beta_{j}x_j)-(\beta_0+\sum_{j=1}^{p}E(\beta_{j}X_{j}))\\=&\hat{f}(x)-E(\hat{f}(X))\end{align*}

This is the predicted value for the data point x minus the average predicted value.
Feature contributions can be negative.
These also happen to be Shapley values.
Maybe you agree with me that for the linear case they are quite intuitive.
But for now you just have to trust me that these are Shapley values.
Because we have yet to define what Shapley values are.
So that we can apply them to more complex predictive models as well.

## How Shapley values are defined

The Shapley value is defined via a value function $val$ of players in S.

The Shapley value of a feature value is its contribution to the payout, weighted and summed over all possible feature value combinations:

$$\phi_j(val)=\sum_{S\subseteq\{1,\ldots,p\} \backslash \{j\}}\frac{|S|!\left(p-|S|-1\right)!}{p!}\left(val\left(S\cup\{j\}\right)-val(S)\right)$$

where S is a subset of the features used in the model, x is the vector of feature values of the instance to be explained and p the number of features.
$val_x(S)$ is the prediction for feature values in set S that are marginalized over features that are not included in set S:

$$val_{x}(S)=\int\hat{f}(x_{1},\ldots,x_{p})d\mathbb{P}_{x\notin{}S}-E_X(\hat{f}(X))$$

You actually perform multiple integrations for each feature that is not contained S.
A concrete example:
The machine learning model works with 4 features x1, x2, x3 and x4 and we evaluate the prediction for the coalition S consisting of feature values x1 and x3:

$$val_{x}(S)=val_{x}(\{1,3\})=\int_{\mathbb{R}}\int_{\mathbb{R}}\hat{f}(x_{1},X_{2},x_{3},X_{4})d\mathbb{P}_{X_2X_4}-E_X(\hat{f}(X))$$

This looks similar to the feature contributions in the linear model!

Do not get confused by the many uses of the word "value":
The feature value is the numerical or categorical value of a feature and instance;
the Shapley value is the feature contribution to the prediction;
the value function is the payout function for coalitions of players (feature values).


## The axioms behind Shapley values

Okay, now we have the formula, but where did it even come from?
Lloyd Shapley derived it.[@shapley1953value]
But he didn't just "invent" it.
He postulated some axioms that he said have to be fulfilled so that the resulting attributions would end up being "fair".

The Shapley value is the only attribution method that satisfies the properties **Efficiency**, **Symmetry**, **Dummy** and **Additivity**,  which together can be considered a definition of a fair payout.
We won't derive why and how Shapley values are the solution to these axioms.
But we will walk through the axioms as they have implications for interpretation of the Shapley values.
And they are also the justification of why to use Shapley values (or why for some cases you might not be interested in them).

**Efficiency**
The feature contributions must add up to the difference of prediction for x and the average.

$$\sum\nolimits_{j=1}^p\phi_j=\hat{f}(x)-E_X(\hat{f}(X))$$

Implications: The efficiency axiom is very typical in explainable AI, and also e.g. LIME follows this axiom. The efficiency axiom has a kind of anchoring effect so that the attributions are on the same scale as the output. An example of interpretation without that anchoring effect of efficiency: When we would only look at the gradients of the predicted score with regards to the inputs, these gradients would be on a different scale and not add up to the prediction.

**Symmetry**
The contributions of two feature values j and k should be the same if they contribute equally to all possible coalitions.
If

$$val(S \cup \{j\})=val(S\cup\{k\})$$

for all

$$S\subseteq\{1,\ldots, p\} \backslash \{j,k\}$$

then

$$\phi_j=\phi_{k}$$

Implications: The symmetry axiom means that e.g. the order of features shouldn't matter. If they equally contribute, they should get the same Shapley value.
There are other methods such as the breakdown method [@staniak2018explanations] or counterfactual explanations that violate this axiom and two features could have the same impact on the prediction, but not get the same attribution.
This axiom is a requirement so that we may actually interpret the ordering of the impacts (the attribution values). 


**Dummy**
A feature j that does not change the predicted value -- regardless of which coalition of feature values it is added to -- should have a Shapley value of 0.
If

$$val(S\cup\{j\})=val(S)$$

for all

$$S\subseteq\{1,\ldots,p\}$$

then

$$\phi_j=0$$


Implications: The dummy axiom ensures that features that aren't used by the model get an attribution of zero. Pretty straightforward implication. Let's say a LASSO model was trained, then we can be sure that a feature that got an $\beta_j=0$ has a Shapley value equal to zero for this feature for all possible data points.

**Additivity**
For a game with combined payouts val+val^+^ the respective Shapley values are as follows:

$$\phi_j+\phi_j^{+}$$


Implication: Not as straightforward as the other axioms. But let's give it a try:
Suppose you trained a random forest, which means that the prediction is an average of many decision trees.
The Additivity property guarantees that for a feature value, you can calculate the Shapley value for each tree individually, average them, and get the Shapley value for the feature value for the random forest.
For an additive ensemble of models the Shapley value is the sum of individual Shapley values.

Next chapter will also be more on the theory side of things: How to estimate Shapley values.
Because having just one method would be too simple.

There is an alternative formulation of Shapley values where the Dummy and Additivity axioms are replaced with a Linearity axiom.
But both formulations lead to the Shapley values.


