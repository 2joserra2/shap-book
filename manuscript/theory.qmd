# Theory of Shapley Values

Keep in mind, you don't need to read this chapter if you only want to use Shapley values.
It's intended for those who want to explore the mathematics behind them.

## Mathematical terms used

But before we begin, here is an overview of the terms so you can come back here whenever you feel uncertain about a mathematical term.

| Symbol | Description |
|--------|-------------|
| $\hat{f}(x)$ | The prediction for the instance $x$ using the model $\hat{f}$. |
| $\beta_0, \beta_1, \ldots , \beta_p$ | The coefficients or weights of the linear model. They quantify the impact of each feature on the prediction.|
| $x_1, \ldots, x_p$ | These represent the feature values of the instance $x$. Each feature is indexed by a subscript number.|
| $x_j$ | This represents the j-th feature value of the instance $x$.|
| $\phi_j(\hat{f})$ | This represents the contribution of the j-th feature to the prediction $\hat{f}(x)$.|
| $E(\hat{f}(X))$ | The expected (or average) prediction of the model $\hat{f}$ over all instances in the data.|
| $p$ | The total number of features in the instance $x$.|
| $val_{\hat{f}, x}$ | The value function for a game, which maps from a coalition to the payout. In the case of ML from feature coalitions to prediction minus expected prediction. $val: 2^p \mapsto \mathbb{R}$|

Let's begin with a linear prediction model, as it's easier to comprehend.

## Shapley values for linear models

Our goal in this section is to define Shapley values when the underlying model is a linear regression model.
We want to understand how each feature affects the prediction of a data point.
In a linear model, calculating the individual effects is straightforward.
Here's what a linear model prediction looks like for one data instance:

$$\hat{f}(x)=\beta_0+\beta_{1}x_{1}+\ldots+\beta_{p}x_{p}$$

where x is the instance for which we want to compute the contributions.
Each $x_j$ is a feature value, with j = 1,...,p.
The $\beta_j$ is the weight corresponding to feature j.

The contribution $\phi_j$ of the j-th feature on the prediction $\hat{f}(x)$ is:

$$\phi_j(\hat{f})=\beta_{j}x_j-E(\beta_{j}X_{j})=\beta_{j}(x_j - E(X_{j}))$$

Where $E(\beta_jX_{j})$ is the mean effect estimate for feature j, the contribution is the difference between the feature effect and the average effect.
Nice!
Now we know how much each feature contributed to the prediction.
If we sum all the feature contributions for one instance, the result is the following:

\begin{align*}\sum_{j=1}^{p}\phi_j(\hat{f})=&\sum_{j=1}^p(\beta_{j}x_j-E(\beta_{j}X_{j}))\\=&(\beta_0+\sum_{j=1}^p\beta_{j}x_j)-(\beta_0+\sum_{j=1}^{p}E(\beta_{j}X_{j}))\\=&\hat{f}(x)-E(\hat{f}(X))\end{align*}

This is the predicted value for the data point x minus the average predicted value.
Feature contributions can be negative.

Until now, you had to believe me that for a linear model, the formula above indeed are related to Shapley values.
Let's actually see the definition of Shapley values for the general case.

## How Shapley values are defined

The Shapley values require a value function $val$ which determines a payout and which takes a set of players $S$ (in our case feature values of a data point) as input.
The Shapley value of a feature value is then defined as its contribution to the payout, calculated as a weighted sum over all possible feature value combinations:

$$\phi_j(val)=\sum_{S\subseteq\{1,\ldots,p\} \backslash \{j\}}\frac{|S|!\left(p-|S|-1\right)!}{p!}\left(val\left(S\cup\{j\}\right)-val_{hat{f},x}(S)\right)$$

Here, S represents a subset of the features used in the model, j is the index of the feature for which we compute the Shapley value, $S$ a coalition of some features (without $j$), and $p$ is the number of features in the model.
$val_{hat{f},x}(S)$ is the prediction for feature values in set S, marginalized over features not included in set S:

$$val_{hat{f},x}(S)=\int\hat{f}(x_{1},\ldots,x_{p})d\mathbb{P}_{X_{\bar{S}}}-E_X(\hat{f}(X))$$

You actually perform multiple integrations for each feature not contained in S ($X_{\bar{S}}$).
Consider this example:
A machine learning model works with four features $X_1$, $X_2$, $X_3$, and $X_4$, and we evaluate the prediction for the coalition S consisting of feature values $X_1$ and $X_3$:
$$val_{hat{f},x}(S) = val_{x}(\{1, 3\}) = \int_{\mathbb{R}}\int_{\mathbb{R}}\hat{f}(x_{1}, X_{2}, x_{3}, X_{4})d\mathbb{P}_{X_2X_4} - E_X(\hat{f}(X))$$

This is similar to the feature contributions in a linear model.

:::{.callout-note}

Don't be confused by the different uses of the word "value":
The feature value refers to the numerical or categorical value of a feature and instance;
the Shapley value represents the feature's contribution to the prediction;
the value function is the payout function for coalitions of players (feature values).

:::

## The axioms behind Shapley values

Okay, now we have the formula, but where did it even come from?
Lloyd Shapley derived it [@shapley1953value].
But he didn't just "invent" it.
He postulated some axioms that he said must be fulfilled for the resulting attributions to be considered "fair".

The Shapley value is the only attribution method that satisfies the properties **Efficiency**, **Symmetry**, **Dummy**, and **Additivity**, which together can be considered a definition of a fair payout.
We won't derive why and how Shapley values are the solution to these axioms.
But we will walk through the axioms, as they have implications for the interpretation of Shapley values.
And they also justify the use of Shapley values (or why, in some cases, you might not be interested in them).

### Efficiency

The feature contributions must add up to the difference between the prediction for x and the average.

$$\sum_{j=1}^p\phi_j = \hat{f}(x) - E_X(\hat{f}(X))$$

Implications: 
The efficiency axiom is quite common in explainable AI, and it's also followed by methods like LIME. 
The efficiency axiom provides an anchoring effect, ensuring that the attributions are on the same scale as the output. 
An example of interpretation without this anchoring effect of efficiency would be examining only the gradients of the predicted score concerning the inputs. 
These gradients would be on a different scale and would not add up to the prediction.

### Symmetry

The contributions of two feature values j and k should be the same if they contribute equally to all possible coalitions.

If

$$val_{\hat{f},x}(S \cup \{j\}) = val_{hat{f},x}(S \cup \{k\})$$

for all

$$S \subseteq \{1, \ldots, p\} \backslash \{j, k\}$$

then

$$\phi_j = \phi_{k}$$

Implications: 
The symmetry axiom implies that, for example, the order of features should not matter.
If they contribute equally, they should receive the same Shapley value.
Other methods, such as the breakdown method [@staniak2018explanations] or counterfactual explanations, violate this axiom, and two features could have the same impact on the prediction without receiving the same attribution.
This axiom is a requirement for us to accurately interpret the ordering of the Shapley values.

### Dummy

A feature j that does not change the predicted value – regardless of which coalition of feature values it's added to – should have a Shapley value of 0.

If

$$val_{hat{f},x}(S \cup \{j\}) = val_{hat{f},x}(S)$$

for all

$$S \subseteq \{1, \ldots, p\}$$

then

$$\phi_j = 0$$

Implications: 
The dummy axiom ensures that features not used by the model receive an attribution of zero. 
This is a straightforward implication.
For example, if a LASSO model was trained, we can be certain that a feature with a $\beta_j = 0$ will have a Shapley value of zero for this feature for all possible data points.

For a game with combined payouts val+val^+^, the respective Shapley values are as follows:

$$\phi_j+\phi_j^{+}$$

$$\phi_j + \phi_j^+$$

Implications:
Suppose you trained a random forest, which means that the prediction is an average of many decision trees. 
The Additivity property guarantees that for a feature value, you can calculate the Shapley value for each tree individually, average them, and obtain the Shapley value for the feature value for the random forest. 
For an additive ensemble of models, the Shapley value is the sum of individual Shapley values.

::: {.callout-note}

There exists an alternative formulation of Shapley values in which the Dummy and Additivity axioms are replaced with a Linearity axiom; however, both formulations ultimately lead to the Shapley values.

:::


## Interaction Index

Each feature gets assigned one Shapley value and the sum of Shapley values yields the prediction.
Any interactions between feature values are fairly shared between them.
But sometimes it can be interesting to not fairly share them, but instead attribute the prediction also to two-way interactions between features.
For interactions there is also a solution called interaction index.

The Shapley interaction index, derived from game theory, is defined as:

$$\phi_{i,j}=\sum_{S\subseteq\backslash\{i,j\}}\frac{|S|!(M-|S|-2)!}{2(M-1)!}\delta_{ij}(S)$$
when $i\neq{}j$ and:

$$\delta_{ij}(S)=\hat{f}_x(S\cup\{i,j\})-\hat{f}_x(S\cup\{i\})-\hat{f}_x(S\cup\{j\})+\hat{f}_x(S)$$

This formula removes the main effects of the features, resulting in the pure interaction effect after accounting for individual effects.
We then average the values over all possible feature coalitions $S$, similar to the Shapley value computation.
By calculating the SHAP interaction values for all features, we obtain one matrix per instance with dimensions M x M, where M represents the number of features.


The next chapter will delve deeper into the theoretical side of things, focusing on how to estimate Shapley values, because having just one method would be too simplistic.
