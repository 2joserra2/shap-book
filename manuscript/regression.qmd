# Regression

In this chapter, we will revisit the wine data and fit a tree-based model.
This means the model potentially includes numerous interactions and non-linear functions, resulting in a more complex interpretation compared to previous chapters.
But, on the good side, we can utilize the fast `shap.TreeExplainer`.

## Fitting the LightGBM model

If you haven't installed LightGBM yet, install it as follows:

```{python}
#| eval: false
pip install lightgbm
```

LightGBM is a gradient boosting framework based on decision trees.
It's fast, efficient, and generally performs well.
Using a histogram-based approach to represent feature values, it excels with large datasets.
But enough advertisement, let's train the LightGBM model.

```{python}
import pandas as pd
import lightgbm as lgb
import shap
from sklearn.model_selection import train_test_split

# Load the dataset
wine = pd.read_csv("wine.csv")

y = wine["quality"]
X = wine.drop(columns=["quality"])

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
  X, y, test_size=0.2, random_state=42
)

# Create LightGBM dataset
train_data = lgb.Dataset(X_train, label=y_train)
test_data = lgb.Dataset(X_test, label=y_test)

# Train the model
model = lgb.LGBMRegressor()
model.fit(X_train, y_train)
```

Again, we evaluate the performance of our solution, hoping for better results than with just the GAM:

```{python}
from sklearn.metrics import mean_absolute_error

# Make predictions on the test data
y_pred = model.predict(X_test)
# Compute the MAE
mae = mean_absolute_error(y_test, y_pred)

print('MAE:', round(mae, 2))

```

Once again, this model performs slightly better than the GAM, justifying the inclusion of additional interactions.
Notably, the GAM was also tree-based but without modeling interactions.


## Computing SHAP values

Now let's interpret the model:

```{python}
import shap
# Compute the SHAP values for the sample
explainer = shap.Explainer(model)
shap_values = explainer(X_test)
```

For this model, `shap` can automatically extract the data for the background data.

Let's again have a look at this wine that we already examined in the [Linear Chapter](#linear) and the [Additive Chapter](#additive).

```{python}
# Visualize the SHAP values
shap.plots.waterfall(shap_values[0])
```

The results differ from both the linear and the GAM models, but the interpretation process remains similar.
We still need to interpret the SHAP values, but now we also consider interactions between feature values that have been fairly split among them.
These interactions are not visible in this plot.

## Global model interpretation

Global SHAP plots enable us to see how features impact the overall predictions in the model.
Let's examine the summary plot:

```{python}
shap.summary_plot(shap_values, X_test)
```

Observations:

- Alcohol and volatile acidity were the most important features.
- Many features, such as alcohol and volatile acidity, show a (somewhat) monotonic relationship with the target.
- Factors that influenced the predicted quality of some wines in the most extreme ways included:
  - High alcohol levels for higher predicted quality.
  - Low levels of free sulfur dioxide for lower quality.

The interactions can be analyzed in the global plots such as the dependence plots.
Here is the dependence plot for the alcohol feature:

```{python}
shap.dependence_plot(
  "alcohol", shap_values.values, X_test,
  feature_names=wine.columns
)
```

The shap package automatically selects the `volatile acidity` feature for interaction detection, coloring the SHAP values accordingly.
The feature `volatile acidity` was picked because it had the highest estimated interaction with `alcohol`.

::: {.callout-note}

## Automatic Interaction Detection

By default, the `shap` dependence plot picks the feature that has the strongest interaction with the feature of interest.
The dependence plot function calls the  `approximate_interactions` function which measures interaction between features through correlation of SHAP values, with stronger correlation indicating stronger interaction.
It then returns a ranking of features based on their interaction strength with a selected feature.
You can also pick a feature by hand.

:::


Some key observations:

- Generally, an increase in alcohol level raises the SHAP value, which in turn increases the predicted values.
- Examining cases with low volatile acidity reveals an interesting interaction with wines that have a low alcohol level. While wines with low alcohol (around 9%) typically have a negative SHAP value, low volatile acidity seems to have a slightly positive impact.
- When alcohol levels are high (11 - 14%), having a higher volatile acidity appears to be slightly beneficial, though the effect is quite subtle.

::: {.callout-note}
General advice on reading the interaction part of the dependence plot:

- Choose one of the two variables.
- For this variable, select two ranges or categories.
- Compare the SHAP values within these ranges.
- Observe if any differences are associated with changes in the other feature.

:::

Now, let's examine the partial dependence plot for residual sugar.
Residual sugar indicates the remaining sugar in the wine, with higher amounts making it sweeter.

```{python}
shap.dependence_plot(
  'residual sugar', shap_values.values, X_test,
  feature_names=wine.columns
)
```


Observations:

- Higher residual sugar corresponds to higher SHAP values.
- The `shap` package identifies the highest interaction with density.
- Density and residual sugar are correlated (not independent); for instance, high sugar levels result in high density values. Physics.
- Comparing curves for low density (around 0.99) and high density (around 0.998):
  - When density is low, increasing residual sugar has a significant increasing effect.
  - If density is high, increasing residual sugar doesn't have as strong an effect.

