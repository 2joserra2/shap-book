# Multi-Class Classification With Random Forests {#multiclass}

TODO: Turn into multi-label??

In this chapter, we will focus on:

- Multi-class classification for tabular data
- Handling multi-class problems
- Probability versus class

TODO: Copy from here: https://github.com/slundberg/shap/blob/master/notebooks/tabular_examples/tree_based_models/Census%20income%20classification%20with%20XGBoost.ipynb

For binary classification, we typically have two outputs: one probability output for the first class and one for the second.
However, since the probability of one class defines the probability of the other, we can work with just one probability.

From the SHAP perspective, this is similar to regression, except that the scale is not regression but the score output.

```{python}
import shap
X,y = shap.datasets.adult()
```

Next, we train the model:

```{python}
from sklearn.neighbors import KNeighborsClassifier

model = KNeighborsClassifier()
model.fit(X, y)
```

```{python}
ex = shap.Explainer(model.predict_proba, X.iloc[0:20,:])
```

```{python}
shap_values = ex(X.iloc[0:10,:])
```

```{python}
class_index= 0

sv = shap.Explanation(values = shap_values.values[0,:,class_index],
                      base_values = shap_values.base_values[0,class_index],
                      feature_names=X.columns)
shap.waterfall_plot(sv)
```
```{python}
#| scrolled: true
class_index = 1

sv = shap.Explanation(values=shap_values.values[0, :, class_index],
                      base_values=shap_values.base_values[0, class_index],
                      feature_names=X.columns)
shap.waterfall_plot(sv)
```

_TODO: Provide an interpretation for this data point using automated text with strings and variables._

We can also analyze a different class by selecting another class index.
The resulting plot will have its signs flipped, which makes sense since the probabilities are also inverted.

## Understanding the data globally

```{python}
#| scrolled: true
shap.summary_plot(shap_values.values[:, :, 1])
```

The resulting plot is difficult to interpret and doesn't convey much information.
We need to provide more details for the plot to be meaningful:

```{python}
shap.summary_plot(shap_values.values[:, :, 1], features=X.iloc[0:10, :])
```

Now we can clearly understand the plot!

_TODO: Interpret the plot._

```{python}
shap.dependence_plot("Capital Gain", shap_values.values[:, :, 1], features=X.iloc[0:10, :])
```

```{python}
shap.summary_plot(shap_values.values[0])
```

```{python}
?shap.summary_plot
```

## Working with the link argument
- The `Explainer` has two significant arguments:
  - `link`: A function representing the link function that maps the model output to the SHAP value's units. The default is the identity function $f(x)=x$, which doesn't change anything. A useful choice is the logit (shap.links.logit) function when the model outputs probabilities. This is because probabilities are typically not additive, but log-odds are, and the logit function provides the log-odds.
  - `linearize_link`: Accepts a boolean (`true`/`false`) value. The default is `true`. This argument becomes relevant when the `link` function is non-linear (not the default identity function). It is also applicable when the background masker uses more than one data point.

Consider experimenting with different `linearize_link` values using the adult dataset and various models.
## Multi-Class Classification

Look for a multi-class example.

Demonstrate how to select different classes.
