# Other Applications of Shapley Values in Machine Learning

This chapter explores how Shapley values can be applied to various tasks in machine learning beyond prediction explanations.
While the [Extensions Chapter](#extensions) focused on extensions for explaining predictions, this chapter presents other machine learning and data science tasks that can benefit from Shapley values. This chapter draws on the overview paper by @rozemberczki2022shapley.

## Feature importance based on loss function

SAGE [@covert2020understanding] is a model-agnostic method that quantifies the predictive power of individual features while accounting for feature interactions. In this approach, the model training is considered the "game," individual features are the "players," and the overall performance is the "payout." SAGE differs from SHAP importance plots as it evaluates features at a global level, rather than combining individual effects. The interpretation is based on the loss function, not on the (absolute) prediction output. SAGE can be used to understand sub-optimal models and identify corrupted or incorrectly encoded features.
Similarly, @redell2019shapley proposed fairly distributing the R-squared of a model using Shapley values.

## Feature selection

Closely related to SAGE is feature selection, which involves identifying the best features for model performance. Shapley values can be applied to the modeling process, as suggested by @guyon2003introduction and @fryer2021shapley. By repeatedly training the model with different features, the importance of each feature for performance can be estimated. However, @fryer2021shapley argue that Shapley values may not be ideal for this task, as they are better suited for attribution rather than selection. Despite this limitation, each feature is treated as a player, with model performance as the payoff. Unlike Shapley values for prediction, the contribution of each feature is evaluated globally for the model. The ultimate goal is to determine how much each feature contributes to model performance.

## Data valuation
Data valuation is the process of evaluating the importance of each input data in a machine learning model.
Shapley values can be employed to solve this problem, as demonstrated by "Data Shapley"[@ghorbani2019data].
In this approach, data points in the training set are considered players, and the payoff is determined by the evaluation metrics or model's goodness of fit on the test data.
This method is akin to deletion diagnostics such as Cook's Distance.
An application of Data Shapley can be found in a paper by Bloch et al.[@bloch2021data], where they used it to select patient data for an Alzheimer detection model.

## Model valuation in ensembles

In an ensemble of multiple models, the ensemble's performance should ideally surpass that of each individual model.
Each model is considered a player, and the payout is determined by the ensemble's overall performance.
Shapley values ensure a fair payout, as seen in cases like Numerai, where external participants train multiple models and receive a payout based on their performance.
However, to the best of my knowledge, Shapley values are not used in Numerai's payouts.

## Federated learning

Federated learning aims to train a machine learning model on private data distributed across multiple entities, such as hospitals.
In this scenario, each hospital is a player contributing to the model's training.
Federated learning enables training models across multiple private datasets while maintaining privacy.
The payout is determined by the model's goodness of fit or other performance metrics, which estimate each entity's contribution.

## And many more

The list is not exhaustive, and you might even extend it.
Shapley values are a versatile method.
Whenever you need to distribute a numerical outcome among entities, consider using Shapley valuesâ€”whether in machine learning, data science, or beyond.
