# Other Applications of Shapley Values in ML


This chapter takes a step back from the Shapley values for prediction only and looks at how Shapley values can be used for other things in machine learning.

While the [extensions chapter](extensions) focused on extensions where still the goal was to explain predictions and the overall "game" was roughly the same, this chapter presents other nails to which Shapley values is the hammer.

Here is a list of tasks around the topic of ML and data science, for which Shapley values can be used.
This chapter is partially based on the overview paper by @rozemberczki2022shapley.

## Feature importance based on loss function


SAGE[@covert2020understanding] is a model-agnostic method that quantifies predictive power of individual features while accounting for feature interactions.
The game is the model training, the players are the individual features, and the payout is the overall performance.
So SAGE differs from SHAP importance plot as SAGE targets the features on a global level instead of combining the individual effects into a global one and the interpretation is on the level of loss function and not on the level of the (absolute) prediction output.
SAGE can be used to understand sub-optimal models and identify features that are corrupted or incorrectly encoded.

Similarly [@redell2019shapley] has proposed to fairly distribute the R-squared of a model.

## Feature selection

Highly related to SAGE is feature selection.
Feature selection is the process of identifying the best features for model performance.
This can be done using Shapley values applied to the modeling process instead of the model itself, as suggested by @guyon2003introduction and @fryer2021shapley.
By repeatedly training the model with different features, the importance of each feature for performance can be estimated.
However, @fryer2021shapley argue that Shapley values may not be ideal for this job since they are more suited for attribution rather than selection.
Despite this limitation, each feature is treated as a player, with model performance as the payoff.
Unlike shape for prediction, the contribution of each feature is evaluated globally for the model.
The ultimate goal is to determine how much each feature contributes to model performance.



## Data valuation

Data valuation is a process of evaluating the importance of each input data in a machine learning model.
And this too can be solved with Shapley values, for example with "Data Shapley"[@ghorbani2019data].
In this process, the data points in the training data are considered as players, and the payoff is determined by the evaluation metrics or goodness of fit of the model on the test data. 
This approach is similar to deletion diagnostics such as Cook's Distance.
An example of its application can be found in a paper by Bloch et al.[@bloch2021data], where they used Data Shapley to select patient data for an Alzheimer detection model.


## Model valuation in ensembles

When multiple models form an ensemble, the ensemble's performance should ideally exceed that of each individual model.
Each model in the ensemble is considered a player.
The payout is determined by the performance of the entire ensemble.
Shapley values are used to ensure a fair payout, sometimes quite literally, as in the case of Numerai, where multiple models are trained by external participants who receive a payout based on their performance.
However, to the best of my knowledge, Shapley values are not utilized in Numerai's payouts.

## Federated learning

Federated learning aims to train an ML model on private data spread across multiple entities, such as hospitals.
In this example, each hospital is a player who contributes to the training of the model.
Federated learning allows for the model to be trained across multiple private datasets.
The payout is the goodness of fit or other model performance metrics, which estimate the contribution of each entity.
Overall, federated learning is a useful approach to train models on sensitive data while maintaining privacy.



## The types of tasks Shapley values can be used for

The list is not complete and you might even make it longer.
Shapley values is such a general method.
So whenever you have the problem of distributing some type of numerical outcome to some entities, you can consider using Shapley values -- whether it's within machine learning, data science in general or outside of those areas.



