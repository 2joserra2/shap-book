# Other Uses of Shapley Values in Machine Learning

This chapter explores the various applications of Shapley values in tasks within the machine learning field beyond prediction explanations.
While the [Extensions Chapter](#extensions) focused on extensions for explaining predictions, this chapter introduces other tasks in machine learning and data science that can benefit from the use of Shapley values.
The information in this chapter is based on the overview paper by @rozemberczki2022shapley.

## Feature importance determination based on loss function

SAGE [@covert2020understanding] is a model-agnostic method for quantifying the predictive power of individual features while taking into account feature interactions.
In this approach, model training is seen as the "game," individual features are the "players," and the overall performance is the "payout."
SAGE differs from SHAP importance plots as it assesses features at a global level, instead of combining individual effects.
The interpretation is based on the loss function, rather than the absolute prediction output.
SAGE can be utilized to understand sub-optimal models and identify corrupted or incorrectly encoded features.
In a similar manner, @redell2019shapley proposed a fair distribution of a model's R-squared using Shapley values.

## Feature selection

Feature selection, a process closely related to SAGE, involves identifying the features that best enhance model performance.
Shapley values can be incorporated into the modeling process, as suggested by @guyon2003introduction and @fryer2021shapley.
By repeatedly training the model using different features, it is possible to estimate each feature's importance to performance.
However, @fryer2021shapley argue that Shapley values may not be ideally suited for this task, as they excel in attribution rather than selection.
Despite this limitation, each feature is treated as a player, with the model performance being the payoff.
Unlike SHAP values for prediction, the contribution of each feature is evaluated globally for the entire model.
The ultimate goal is to ascertain each feature's contribution to the model's performance.

## Data valuation

Data valuation refers to the process of evaluating the importance of each input data in a machine learning model.
Shapley values can be used to address this problem, as illustrated by "Data Shapley"[@ghorbani2019data].
In this approach, data points in the training set are considered players, and the payoff is determined by evaluation metrics or the model's goodness of fit on the test data.
This method is similar to deletion diagnostics such as Cook's Distance.
An application of Data Shapley is presented in a paper by Bloch et al.[@bloch2021data], where it was used to select patient data for an Alzheimer detection model.

## Model valuation in ensembles

In an ensemble of multiple models, the overall performance of the ensemble ideally exceeds that of each individual model.
Each model is considered a player, and the payout is determined by the ensemble's total performance.

## Federated learning

Federated learning is a method to train a machine learning model on private data distributed across multiple entities, such as hospitals.
In this context, each hospital is a player that contributes to the training of the model.
Federated learning facilitates training models across various private datasets while maintaining privacy.
The payout is determined by the model's goodness of fit or other performance metrics, which estimate the contribution of each entity.

## And many more

This list is far from exhaustive, and it is possible to expand it even further.
Shapley values are a versatile method.
Whenever you need to distribute a numerical outcome among several entities, consider using Shapley values, whether in machine learning, data science, or other fields.
